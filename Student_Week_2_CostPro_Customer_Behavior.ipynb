{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXQ3XjnpefVr"
      },
      "source": [
        "# Week 2: CostPro Customer Behavior\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸš¨ **First things first! Make a copy of this notebook. Your changes will not save unless you create your own copy!**"
      ],
      "metadata": {
        "id": "unR5HV2ezi6_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aK-J2GoefVt"
      },
      "source": [
        "ðŸ’¡ Build Intuition\n",
        "\n",
        "As a data scientist at CostPro, your goal is to collect and analyze data on various factors influencing the likelihood of a purchase, such as a customer's past purchasing history, online behavior, and demographic information.\n",
        "\n",
        "You'll use probability distributions to model customer behavior, to determine how likely different outcomes are."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cloRwMmTVEk1"
      },
      "source": [
        "## ðŸš€ Project Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need to download and import all of the dependencies that we will need for the project"
      ],
      "metadata": {
        "id": "kidKo1sn4ZxV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4yXMQCYVvQP"
      },
      "source": [
        "### Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alHjfjNjVyMd"
      },
      "outputs": [],
      "source": [
        "# Install all required dependencies for the project\n",
        "!pip install -qqq numpy pandas seaborn matplotlib gdown plotly scipy\n",
        "# We need this to avoid version incompatibilities between packages (please ignore any warnings)\n",
        "!pip install --force-reinstall --ignore-installed -qqq protobuf==3.20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8ja3Pn-V5qM"
      },
      "outputs": [],
      "source": [
        "# Import dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import shutil\n",
        "from scipy.stats import poisson, binom, norm, skew, kurtosis, probplot, loggamma\n",
        "import gdown\n",
        "from google.colab import files\n",
        "\n",
        "# [TO BE IMPLEMENTED]\n",
        "# Feel free to add any other imports that you need to write your own custom metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6PBDWHba3ML"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Online Retail](https://archive.ics.uci.edu/ml/datasets/online+retail) is a collection of roughly 400,000 records from an international online retail dataset. For this project, we will use a slightly modified (cleaned up) version of this dataset as the sales data for CostPro."
      ],
      "metadata": {
        "id": "kfkh8pwB5cLF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBpKXQayVG-W"
      },
      "source": [
        "### Download the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDSJ32UfcXlp"
      },
      "outputs": [],
      "source": [
        "# Download the file from co:rise google drive\n",
        "file_name = \"online_retail.csv\"\n",
        "unique_id = \"16HZKULqv2sX6AMqi4A8ndQ9ULeCLo4Qt\"\n",
        "gdown.download(id=unique_id, output=file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to create a directory. This will be used to store the files that you will need to produce your dashboard."
      ],
      "metadata": {
        "id": "gsybLSI453SX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the directory\n",
        "!mkdir -p retail_metrics_dashboard"
      ],
      "metadata": {
        "id": "VsClGC_cboYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjJgWHSpVLCG"
      },
      "source": [
        "### Clean & Prepare the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll import the data as a pandas dataframe. The code below will show you the first 5 rows of the dataframe, but feel free to explore the data further!"
      ],
      "metadata": {
        "id": "ggz-ny2U6FQn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vHVNKpadgNE"
      },
      "outputs": [],
      "source": [
        "# import data and show first 5 rows\n",
        "data = pd.read_csv(file_name)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddQHZwyOa3MN"
      },
      "source": [
        "## Project Jumpstart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZpxbAMyfGwI"
      },
      "source": [
        "### Explore Basic Statistics You Get Out of the Box with Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuxfW2EBfguL"
      },
      "outputs": [],
      "source": [
        "# check record count and column count\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "updJj9X7flfQ"
      },
      "outputs": [],
      "source": [
        "# review basic information about the dataset including column names, data types, non-null counts, and memory usage\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YpzC3gVf0bH"
      },
      "outputs": [],
      "source": [
        "# check the number of missing values in each column\n",
        "data.isnull().sum(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOlxNAWja3MP"
      },
      "source": [
        "On the job, you'll need to explore if there are specific patterns to the missing values. For the sake of expediency and simplicity in this project, we'll drop them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wm-b3eZygVO3"
      },
      "outputs": [],
      "source": [
        "# Drop missing values and validate that there are no missing values after the fix\n",
        "data = data.dropna().reset_index(drop=True)\n",
        "data.isnull().sum(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYwdj7oCg9iX"
      },
      "outputs": [],
      "source": [
        "# Check the number of unique values in each column\n",
        "data.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Bkh7diza3MP"
      },
      "outputs": [],
      "source": [
        "# Use pandas describe() method to get a summary of the numerical columns\n",
        "basic_stats = data.describe()\n",
        "basic_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to create columns for Year, Month, Day, and Quarter so that your leadership team at CostPro can look at statistics for specific time periods in your dashboard."
      ],
      "metadata": {
        "id": "ZRbJqGMB8KZn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXslL7GvhjnN"
      },
      "outputs": [],
      "source": [
        "# Format date columns\n",
        "# Note: the pandas to_datetime function is being deprecated in the near future\n",
        "data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'])\n",
        "\n",
        "data[\"Year\"] = data[\"InvoiceDate\"].dt.year\n",
        "data[\"Month\"] = data[\"InvoiceDate\"].dt.month\n",
        "data[\"Day\"] = data[\"InvoiceDate\"].dt.day\n",
        "data[\"Quarter\"] = data[\"InvoiceDate\"].dt.quarter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNGnj-_pa3MQ"
      },
      "source": [
        "### Clean the Data\n",
        "\n",
        "Check the basic stats on the numeric data again, what do you notice?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRy122Waa3MQ"
      },
      "outputs": [],
      "source": [
        "basic_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjpz8GGUa3MR"
      },
      "source": [
        "Look at the quantity minimum! `-80995.000000`\n",
        "\n",
        "Let's take a look at the dataset again to figure out what's going on!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i8bLnxEa3MR"
      },
      "outputs": [],
      "source": [
        "# Review records where the quantity is less than 0\n",
        "data[data['Quantity'] < 0].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXj3yIVOa3MR"
      },
      "source": [
        "After closer examination, we can see that both the quantities and pricing are negative. We can also see that the Invoice Numbers are prepended with a `C`.\n",
        "\n",
        "A quick glance at the data docs tells us that \"InvoiceNo: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRCriMLVa3MR"
      },
      "outputs": [],
      "source": [
        "# Create a function to remove cancelled orders\n",
        "def remove_cancelled_orders(data):\n",
        "    # Create a subset of the data that only has cancelled invoices\n",
        "    cancelled_invoices = data[data['InvoiceNo'].str.contains('C')]\n",
        "\n",
        "    # Create a new column that contains the original invoice number\n",
        "    cancelled_invoices['OriginalInvoiceNo'] = cancelled_invoices['InvoiceNo'].str.replace('C', '')\n",
        "\n",
        "    # Filter the dataset to only include invoices that haven't been cancelled\n",
        "    data = data[~data['InvoiceNo'].str.contains('C')]\n",
        "\n",
        "    # Filter the data by the original invoice number on the cancelled invoices\n",
        "    return data[~data['InvoiceNo'].isin(cancelled_invoices['OriginalInvoiceNo'])]\n",
        "\n",
        "data = remove_cancelled_orders(data)\n",
        "\n",
        "display(data.head())\n",
        "\n",
        "# Review the data again to ensure that the cancelled orders have been removed\n",
        "assert data[data['InvoiceNo'].str.contains('C')].shape[0] == 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAWFQG0fa3MR"
      },
      "source": [
        "Great! That's looking much better! Now the minimum quantity is 1.\n",
        "\n",
        "On the job, we'd definitely want to dig into what products get returned and at what rate and factor returns into total sales. For the sake of expediency in this project, we're going to ignore cancellations and returns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJRfHKHhhz7D"
      },
      "source": [
        "### Create Useful Aggregations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHEYqVuRhxEZ"
      },
      "outputs": [],
      "source": [
        "# Create a column that represents the total price of each item\n",
        "data['TotalPrice'] = data['Quantity'] * data['UnitPrice']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq_Vww8oa3MS"
      },
      "outputs": [],
      "source": [
        "# Create a dataframe that represents the total value of each order\n",
        "total_value_per_order = data.groupby('InvoiceNo')['TotalPrice'].sum().to_frame()\n",
        "total_value_per_order.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7NX-Pdya3MV"
      },
      "source": [
        "### Filter Data By Year and Quarter\n",
        "\n",
        "Here's an example, you get the first one for free!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoNC35HFa3MV"
      },
      "outputs": [],
      "source": [
        "# Write a function to filter a pandas dataframe by year and quarter\n",
        "def filter_by_year_and_quarter(df, year, quarter):\n",
        "\n",
        "    # Filter the dataframe by the year and quarter\n",
        "    filtered_df = df[(df['Year'] == year) & (df['Quarter'] == quarter)]\n",
        "\n",
        "    # Return the filtered dataframe\n",
        "    if filtered_df.shape[0] > 0:\n",
        "        return filtered_df\n",
        "    else:\n",
        "        assert filtered_df.shape[0] > 0, \"There are no records for the specified year and quarter\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j43e29MUa3MV"
      },
      "outputs": [],
      "source": [
        "# Create a dataframe that only contains records for 2022 Q4\n",
        "display(filter_by_year_and_quarter(data, 2022, 4).head(5))\n",
        "\n",
        "# Write a test to validate the function\n",
        "assert filter_by_year_and_quarter(data, 2022, 4)['Year'].unique()[0] == 2022, \"There should only be records for 2022\"\n",
        "assert filter_by_year_and_quarter(data, 2022, 4)['Quarter'].unique()[0] == 4, \"There should be records for Q4\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T8zLH1GefWC"
      },
      "source": [
        "## Your Turn\n",
        "\n",
        "Use probability distributions to answer questions that CostPro can use to drive business decisions!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOrqqGSu-pmg"
      },
      "source": [
        "### Are CostPro Prices Normally Distributed?\n",
        "\n",
        "CostPro management is worried that there might be a mismatch between the prices they're charging and the prices that customers are willing to pay. Specifically, they're worried that they're selling too many expensive items, and that customers are mostly buying lower-priced items.\n",
        "\n",
        "Ideally, management would like the distribution of item prices to match the distribution of customer purchase prices.\n",
        "\n",
        "Your job is to plot the distribution of number of sales at each unit price. Are sales normally distributed across unit price?\n",
        "\n",
        "Calculate skew and kurtosis for the distribution. Then create a QQ plots of the distribution, to compare it to a normal distribution.\n",
        "\n",
        "ðŸ’¡ Hint: Are there any libraries/methods we've imported that could help? If you're not sure how to use a method, you can often access documentation by writing `help(function_name)`\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataframe that tells us the total number of sales at each unit price\n",
        "orders_per_price = <YOUR CODE HERE>\n",
        "orders_per_price.head()"
      ],
      "metadata": {
        "id": "RVO8HqYAvItX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a function to check skew and kurtosis\n",
        "def check_skew_kurtosis(column: str, data: pd.DataFrame):\n",
        "\n",
        "    skewness = <YOUR CODE HERE>\n",
        "    kurtosis_value = <YOUR CODE HERE>\n",
        "    print(f'The skew of {column} is {skewness}. A normal distribution should have a skew close to 0\\n' )\n",
        "    print(f'The kurtosis of {column} is {kurtosis_value}. A normal distribution should have a kurtosis close to 0\\n' )\n"
      ],
      "metadata": {
        "id": "S3y4T6zL8q22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Get the skew and Kurtosis for the distribution of the number of sales at each unit price\n",
        "<YOUR CODE HERE>"
      ],
      "metadata": {
        "id": "iODU94i0_HU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Write a function that outputs the QQ plot of a column of data in a dataframe\n",
        "\n",
        "def qq_plot(column: str, data: pd.DataFrame):\n",
        "  <YOUR CODE HERE>"
      ],
      "metadata": {
        "id": "5hNXsjaFApbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display your plot\n",
        "<YOUR CODE HERE>"
      ],
      "metadata": {
        "id": "erab7j0Mwue2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSBYe1hca3MY"
      },
      "source": [
        "### How Likely Is It That CostPro Will Have Enough High-Value Sales?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your boss at CostPro feels that CostPro needs more \"high value\" sales, where a sale is \"high value\" if the total price is over $1000. Management has set a goal of at least 350 high value sales per quarter.\n",
        "\n",
        "Your job is to estimate the likelihood that CostPro will meet this goal. How likely is it to have at least 350 high value sales in a given quarter?\n",
        "\n",
        "To do this, you can model sales as a binomial distribution. Since we're interested only in high value sales, you can count a sale as a \"success\" if it's over \\$1000, and a failure if it's less than \\$1000. To calculate the binomial distribution, you just need the two key values:\n",
        "\n",
        "1. n, the total number of sales in a given quarter (you can use the mean number of sales in a quarter)\n",
        "2. p, the probability that a sale is over \\$1000 (you can use the overall rate at which sales are over \\$1000 in the dataset)\n",
        "\n",
        "In the cells below, use the sales dataset to get the values of n and p, and then use these to generate a binomial distribution. You can then use this binomial distribution to calculate the probability that there will be at least 350 high value sales in a given quarter."
      ],
      "metadata": {
        "id": "-USNkVqdtau0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05wzLlUYa3MY"
      },
      "outputs": [],
      "source": [
        "# Write a function using the Binomial distribution to model the number of sales\n",
        "def customer_purchase_proba(data: pd.DataFrame, year: int, quarter: int) -> float:\n",
        "    \"\"\"\n",
        "    Calculate the probability of a customer arriving on the website in the next 15 minutes\n",
        "    :param data: The dataframe containing the data\n",
        "    :param year: The year to calculate the probability for\n",
        "    :param quarter: The quarter to calculate the probability for\n",
        "    :return: The probability of a customer arriving on the website in the next 15 minutes\n",
        "    \"\"\"\n",
        "    # Filter the data by the given year and quarter\n",
        "    data = filter_by_year_and_quarter(data, year, quarter)\n",
        "\n",
        "    # Calulate the total number of sales\n",
        "    <YOUR CODE HERE>\n",
        "\n",
        "    # Generate the Poisson distribution\n",
        "    <YOUR CODE HERE>\n",
        "\n",
        "    # Calculate the probability of having 10% more customers on a given day\n",
        "    return <YOUR CODE HERE>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJjEgqQXa3MY"
      },
      "outputs": [],
      "source": [
        "# Call the function for 2022 Q4\n",
        "print(f'The probability of having at least 350 high-value sales is: {<YOUR CODE HERE>}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, plot the cumulative distribution function for the binomial distribution."
      ],
      "metadata": {
        "id": "uPL0yS6vrT07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "<YOUR CODE HERE>"
      ],
      "metadata": {
        "id": "Mltcz-IHp9-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODOSbceXa3MY"
      },
      "outputs": [],
      "source": [
        "# Visualize the Binomial distribution\n",
        "<YOUR CODE HERE>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXujxt0T-qoG"
      },
      "source": [
        "### How Likely Is It That CostPro Will Have a 10% Increase in Customers On Any Given Day?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your supervisor wants to know how effective the new marketing campaign is. The day after the campaign was launched, CostPro saw a 10% increase in sales, relative to average number of sales in a day.\n",
        "\n",
        "Your supervisor wants to know: how likely is it that this was due to random chance?\n",
        "\n",
        "To help answer this question, you can model customer behavior using the Poisson distribution. In the cells below, use the Poisson distribution to calculate the probability that CostPro has a 10% increase (over the mean) in customers on a given day."
      ],
      "metadata": {
        "id": "ZyvIQivn5cYB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjKZTHRQ-qoG"
      },
      "outputs": [],
      "source": [
        "# Write a function using the Poisson distribution to model how likely a customer is to arrive on the website in the next 15 minutes\n",
        "def customer_arrival_proba(data: pd.DataFrame, year: int, quarter: int) -> float:\n",
        "    \"\"\"\n",
        "    Calculate the probability of a customer arriving on the website in the next 15 minutes\n",
        "    :param data: The dataframe containing the data\n",
        "    :param year: The year to calculate the probability for\n",
        "    :param quarter: The quarter to calculate the probability for\n",
        "    :return: The probability of a customer arriving on the website in the next 15 minutes\n",
        "    \"\"\"\n",
        "    # Filter the data by the given year and quarter\n",
        "    data = filter_by_year_and_quarter(data, year, quarter)\n",
        "\n",
        "    # Calulate the mean number of customers per day\n",
        "    <YOUR CODE HERE>\n",
        "\n",
        "    # Generate the Poisson distribution\n",
        "    <YOUR CODE HERE>\n",
        "\n",
        "    # Calculate the probability of having 10% more customers on a given day\n",
        "    return <YOUR CODE HERE>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpmqH9nI-qoG"
      },
      "outputs": [],
      "source": [
        "# Call the customer arrival function for 2022 Q4\n",
        "print(f'The probability of having 10% more customers on a given day is: {<YOUR CODE HERE>}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWKJDUUz-qoH"
      },
      "outputs": [],
      "source": [
        "# Write a test to validate the customer arrival function\n",
        "assert <YOUR CODE HERE>, \"There should be no customers for 2022 Q4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ofi8HGe-qoH"
      },
      "outputs": [],
      "source": [
        "# Visualize the Poisson distribution for customer visits\n",
        "def plot_visits_distribution(data):\n",
        "  <YOUR CODE HERE>\n",
        "\n",
        "\n",
        "plot_visits_distribution(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optional\n",
        "\n",
        "As data scientists it's good practice to make liberal use of `assert` statements throughout notebooks to catch unexpected issues.\n",
        "\n",
        "We're often reading in large volumes of data created by someone/some process, and analysis in a notebook created once may be reused on newer data as it comes in. Some basic sense checking can save you a lot of headaches down the line.\n",
        "\n",
        "Examples include:\n",
        "* am I getting the number of rows I expect from this data?\n",
        "* is this column that should never be a null, never actually a null?\n",
        "\n",
        "Can you think of and write some appropriate assert statements?"
      ],
      "metadata": {
        "id": "oZ3a3qkd53ej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optional\n",
        "\n",
        "Come Up With Your Own Question, And Answer It With Probability Distributions"
      ],
      "metadata": {
        "id": "q52baly6wb_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a Dashboard for Your Portfolio!\n",
        "\n",
        "Optional, but ***Highly Encouraged***, Since You've Already Written the Code!\n",
        "\n",
        "To bring our analysis to life we'll be using a toolkit known as Jupyter Widgets, alongside an interactive plot creation library called Plotly.\n",
        "\n",
        "At this stage we don't anticipate that you're necessarily familiar with the ins and outs of how Jupyter Widgets function, but the code and links below should help you get started.\n",
        "\n",
        "You're welcome to modify it as you please. In fact, data visualization is a crucial component of the data science toolkit, so if you're so inclined, give it a try! Some excellent starting points for learning about Jupyter Widgets can be found here, [here](https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20Basics.html), [here](https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html), and [here](https://towardsdatascience.com/bring-your-jupyter-notebook-to-life-with-interactive-widgets-bc12e03f0916)!\n",
        "\n",
        "One potential place to start - can you come up with a better plot type for the data to show outliers? Have a scroll through what the plotly.express library can do [here](https://plotly.com/python/plotly-express/) for inspiration"
      ],
      "metadata": {
        "id": "at-GCM7UK1Wd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from ipywidgets import interact, Select, Output, link\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "# Create a copy of the data we've processed,\n",
        "#  in case we want to modify it some more\n",
        "df = data.copy(deep=True)\n",
        "\n",
        "# Create an output widget\n",
        "out = Output()\n",
        "\n",
        "# Define function to execute on change of filter\n",
        "def metrics_and_visualization(year, quarter):\n",
        "  # Filter the data for the selected year and quarter\n",
        "  filtered_df = filter_by_year_and_quarter(df, year, quarter)\n",
        "\n",
        "  # Sample our data, to make the visualisation less computionationally intensive\n",
        "  filtered_df = filtered_df.sample(frac=0.1, random_state=42)\n",
        "\n",
        "  out.clear_output(wait=True)\n",
        "  with out:\n",
        "    # Display the metrics\n",
        "    print(f\"Q{quarter} Customer Purchase Probability: {customer_purchase_proba(filtered_df, year, quarter)}\")\n",
        "    print(f\"Q{quarter} Customer Arrival Probability: {customer_arrival_proba(filtered_df, year, quarter)}\")\n",
        "\n",
        "    # Visualise the poisson distribution for customer visits\n",
        "    plot_visits_distribution(filtered_df)\n",
        "\n",
        "    # Feel free to add other visualisations here!\n",
        "    # <YOUR CODE>\n",
        "\n",
        "# Create a selection widget to choose the quarter\n",
        "year_widget = Select(options=df[\"Year\"].unique().tolist(), description='Year:')\n",
        "quarter_widget = Select(options=df[\"Quarter\"].unique().tolist(), description='Quarter:')\n",
        "\n",
        "# Display widgets\n",
        "display(year_widget, quarter_widget, out)\n",
        "\n",
        "# Define function to update quarters widget based on the selected year\n",
        "def update_quarters(change):\n",
        "    year = change['new']\n",
        "    quarters = df[df[\"Year\"] == year][\"Quarter\"].unique().tolist()\n",
        "    quarter_widget.options = quarters\n",
        "    quarter_widget.value = quarters[0] if quarters else None\n",
        "\n",
        "# Bind the function to changes in the year widget\n",
        "year_widget.observe(update_quarters, names='value')\n",
        "\n",
        "# Bind the metrics_and_visualization function to changes in the widgets\n",
        "def on_change(change):\n",
        "    metrics_and_visualization(year_widget.value, quarter_widget.value)\n",
        "\n",
        "quarter_widget.observe(on_change, names='value')\n",
        "\n",
        "# Call function once to update quarters and display initial data\n",
        "update_quarters({'new': year_widget.value})\n",
        "metrics_and_visualization(year_widget.value, quarter_widget.value)"
      ],
      "metadata": {
        "id": "k-lyiDXhK44u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We often want to share visualisations like this with our colleagues and let them play around but without exposing them to all the analysis code we took to get there. Luckily we can easily do this in Colab!\n",
        "* go to `Edit` -> `Select All Cells`\n",
        "* go to `View` -> `Show/hide code`\n",
        "\n",
        "You can also go through and collapse individual sections that you don't want to share (e.g. the bit at the top where we installed some python libraries).\n",
        "\n",
        "You can then share a link to the notebook (`Share` -> `Copy Link`, setting the `General Access` field appropriately) and then anyone you share the link with can open the notebook, run through it, and see your analysis!"
      ],
      "metadata": {
        "id": "3yvRklLALI5F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ðŸš€ You Did It!!!\n",
        "\n",
        "Congratulations, you've completed your second assignment in Applied Statistics for Data Science."
      ],
      "metadata": {
        "id": "zjKkn33RLQ4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jhYmtTkmLSzM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}